import json
import re
import random
from pathlib import Path
from typing import Any, Dict, List, Optional

from tqdm import tqdm
import torch  # type: ignore  # –Ω—É–∂–µ–Ω –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ OutOfMemoryError

# --- –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –ø–∞–∫–µ—Ç—ã –ø—Ä–æ–µ–∫—Ç–∞ ---
from bench_utils.model_utils import initialize_model, load_prompt, prepare_prompt  # type: ignore
from bench_utils.metrics import calculate_classification_metrics  # type: ignore

# –ü–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ —Å–∫—Ä–∏–ø—Ç–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
from check_classifiication import (
    get_image_paths as _collect_image_paths,
    get_prediction as _predict_single,
)

# --- –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã ---
PROMPTS_DIR = Path("prompts")
PROMPTS_DIR.mkdir(exist_ok=True)

# –ú–∞–∫—Å–∏–º—É–º –∫–∞—Ä—Ç–∏–Ω–æ–∫, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º—ã—Ö –º–æ–¥–µ–ª–∏ –æ–¥–Ω–æ–º–æ–º–µ–Ω—Ç–Ω–æ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–æ–≤–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
MAX_IMAGES_IN_REQUEST = 4
# –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–æ–ø—É—Å—Ç–∏–º–∞—è –¥–ª–∏–Ω–∞ –≤–∞–ª–∏–¥–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
MIN_PROMPT_LENGTH = 30
# –°–∫–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞ –±—Ä–∞—Ç—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–æ–≤–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
IMAGES_PER_CLASS = 1


# -------------------------------------------------------------
# –£—Ç–∏–ª–∏—Ç—ã
# -------------------------------------------------------------

def extract_prompt_from_output(model_output: str) -> str:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –ø—Ä–æ–º–ø—Ç–∞ –∏–∑ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏.

    –ú–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –æ–±–æ—Ä–∞—á–∏–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ç—Ä–æ–π–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏ –∏–ª–∏ –±–ª–æ–∫–∏ –∫–æ–¥–∞.
    –ú—ã –ø—ã—Ç–∞–µ–º—Å—è –≤—ã—Ç–∞—â–∏—Ç—å –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —Ç–µ–∫—Å—Ç –±–µ–∑ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.
    """
    if not isinstance(model_output, str):
        raise ValueError("–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å—Ç—Ä–æ–∫–æ–π")

    cleaned = model_output.strip()

    # –ü—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å –∏–∑ –±–ª–æ–∫–∞ ```
    code_match = re.search(r"```(?:[a-zA-Z]*)?\s*\n(.*?)\n```", cleaned, re.DOTALL)
    if code_match:
        return code_match.group(1).strip()

    # –ü—Ä–æ–±—É–µ–º —Å–Ω—è—Ç—å –∫–∞–≤—ã—á–∫–∏ –∏ –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ/–∫–æ–Ω—Ü–µ
    return cleaned.strip().strip("\"")


def sample_images_for_improvement(
    dataset_path: Path,
    document_classes: Dict[str, str],
    subset: str,
    images_per_class: int,
) -> List[Path]:
    """–°—ç–º–ø–ª–∏—Ä—É–µ—Ç *images_per_class* –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞."""
    sampled: List[Path] = []
    for class_name in document_classes.keys():
        class_dir = dataset_path / class_name / "images" / subset
        if not class_dir.exists():
            continue

        all_files: List[Path] = [p for p in class_dir.iterdir() if p.is_file()]
        if len(all_files) > images_per_class:
            sampled.extend(random.sample(all_files, images_per_class))
        else:
            sampled.extend(all_files)
    return sampled


def evaluate_prompt(
    model: Any,
    dataset_path: Path,
    document_classes: Dict[str, str],
    subsets: List[str],
    sample_size: Optional[int],
    prompt_template: str,
) -> float:
    """–í—ã—á–∏—Å–ª—è–µ—Ç accuracy –¥–ª—è –ø–µ—Ä–µ–¥–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞."""

    classes_str = ", ".join(f"{idx}: {name}" for idx, name in enumerate(document_classes.values()))
    prompt = prepare_prompt(prompt_template, classes=classes_str)

    y_true: List[str] = []
    y_pred: List[str] = []

    for subset in subsets:
        image_paths = _collect_image_paths(
            dataset_path,
            list(document_classes.keys()),
            subset,
            sample_size,
        )
        for img_path in tqdm(image_paths, desc=f"Eval {subset}"):
            try:
                class_name = img_path.relative_to(dataset_path).parts[0]
            except ValueError:
                class_name = img_path.parts[-5] if len(img_path.parts) >= 5 else "Unknown"

            y_true.append(class_name)
            y_pred.append(_predict_single(model, img_path, prompt, document_classes))

    metrics = calculate_classification_metrics(y_true, y_pred, document_classes)
    return metrics.get("accuracy", 0.0)


def generate_improved_prompt(
    model: Any,
    images: List[Path],
    current_prompt: str,
) -> str:
    """–ó–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç —É –º–æ–¥–µ–ª–∏ —É–ª—É—á—à–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é —Ç–µ–∫—É—â–µ–≥–æ –ø—Ä–æ–º–ø—Ç–∞."""
    instruction = (
        "–í—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–≥–∞–µ—Ç —É–ª—É—á—à–∏—Ç—å —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è "
        "–∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤. –í –æ—Ç–≤–µ—Ç–µ –≤–µ—Ä–Ω–∏—Ç–µ –¢–û–õ–¨–ö–û –Ω–æ–≤—ã–π —Ç–µ–∫—Å—Ç "
        "–ø—Ä–æ–º–ø—Ç–∞ –±–µ–∑ –∫–∞–∫–∏—Ö-–ª–∏–±–æ –ø–æ—è—Å–Ω–µ–Ω–∏–π, –∫–æ–¥–∞ –∏–ª–∏ –∫–∞–≤—ã—á–µ–∫. –¢–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å "
        f"–Ω–µ –∫–æ—Ä–æ—á–µ {MIN_PROMPT_LENGTH} —Å–∏–º–≤–æ–ª–æ–≤. –£–ª—É—á—à–∏—Ç–µ —Å–ª–µ–¥—É—é—â–∏–π –ø—Ä–æ–º–ø—Ç, "
        "—á—Ç–æ–±—ã –º–æ–¥–µ–ª—å —Ç–æ—á–Ω–µ–µ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–ª–∞ –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ —Ç–∏–ø–∞–º:\n\n"
        f"{current_prompt}\n"
    )

    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º batch, —á—Ç–æ–±—ã –Ω–µ —Å–ª–æ–≤–∏—Ç—å OOM
    images_batch = images[:MAX_IMAGES_IN_REQUEST]
    images_str = [str(p) for p in images_batch]

    try:
        model_output = model.predict_on_images(images=images_str, prompt=instruction)
    except torch.cuda.OutOfMemoryError:
        # –§–æ–ª–±—ç–∫: –ø—Ä–æ–±—É–µ–º —Å –æ–¥–Ω–æ–π –∫–∞—Ä—Ç–∏–Ω–∫–æ–π, –µ—Å–ª–∏ –≤—Å—ë –µ—â—ë –ø–∞–¥–∞–µ—Ç ‚Äî —É–±–∏—Ä–∞–µ–º –∫–∞—Ä—Ç–∏–Ω–∫–∏ –≤–æ–≤—Å–µ
        torch.cuda.empty_cache()
        try:
            model_output = model.predict_on_images(images=[images_str[0]], prompt=instruction)
        except Exception:
            # –ü–æ—Å–ª–µ–¥–Ω–∏–π —Ñ–æ–ª–±—ç–∫ ‚Äî –≤—ã–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–π prompt –±–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            print("‚ö†Ô∏è  OOM –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–º–ø—Ç–∞, –ø—Ä–æ–±—É–µ–º –±–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π‚Ä¶")
            model_output = model.predict_on_images(images=[], prompt=instruction)
    except AttributeError:
        # –ù–∞ —Å–ª—É—á–∞–π, –µ—Å–ª–∏ –≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –º–µ—Ç–æ–¥–∞ –∏–Ω–æ–µ.
        model_output = model.predict_on_images(images=images_str, prompt=instruction)  # type: ignore

    return extract_prompt_from_output(model_output)


# -------------------------------------------------------------
# –û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å
# -------------------------------------------------------------

def main() -> None:
    config_path = Path("config_prompt_optimization.json")
    if not config_path.exists():
        msg = (
            "–§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ 'config_prompt_optimization.json' –Ω–µ –Ω–∞–π–¥–µ–Ω. "
            "–°–æ–∑–¥–∞–π—Ç–µ –µ–≥–æ –ø–æ –æ–±—Ä–∞–∑—Ü—É 'config_classification.json'."
        )
        raise FileNotFoundError(msg)

    with config_path.open("r", encoding="utf-8") as f:
        config: Dict[str, Any] = json.load(f)

    task_cfg = config["task"]
    model_cfg = config["model"]
    optim_cfg = config.get("optimization", {})

    dataset_path = Path(task_cfg["dataset_path"])
    prompt_path = Path(task_cfg["prompt_path"])
    subsets = task_cfg["subsets"]
    sample_size = task_cfg.get("sample_size")

    num_attempts: int = int(optim_cfg.get("num_attempts", 5))
    subset_for_improve: str = optim_cfg.get("subset_for_improvement", subsets[0])
    images_per_class: int = IMAGES_PER_CLASS

    # --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ ---
    model = initialize_model(model_cfg)

    # --- –ë–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç ---
    current_prompt_template = load_prompt(prompt_path)
    baseline_acc = evaluate_prompt(
        model,
        dataset_path,
        config["document_classes"],
        subsets,
        sample_size,
        current_prompt_template,
    )
    print(f"–ë–∞–∑–æ–≤–∞—è accuracy: {baseline_acc:.4f}\n")

    best_prompt: str = current_prompt_template
    best_acc: float = baseline_acc

    # --- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è ---
    images_for_update = sample_images_for_improvement(
        dataset_path, config["document_classes"], subset_for_improve, images_per_class
    )
    if not images_for_update:
        raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–æ–±—Ä–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ–º–ø—Ç–∞")

    for attempt in range(1, num_attempts + 1):
        print(f"\n‚û§ –ü–æ–ø—ã—Ç–∫–∞ {attempt}/{num_attempts}")
        candidate_prompt = generate_improved_prompt(
            model, images_for_update, best_prompt
        )

        if (
            not candidate_prompt
            or candidate_prompt == best_prompt
            or len(candidate_prompt.strip()) < MIN_PROMPT_LENGTH
        ):
            print(
                "  ‚ö†Ô∏è  –ú–æ–¥–µ–ª—å –Ω–µ –≤–µ—Ä–Ω—É–ª–∞ –≤–∞–ª–∏–¥–Ω—ã–π –ø—Ä–æ–º–ø—Ç (—Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –∏–ª–∏ –ø–æ–≤—Ç–æ—Ä). –ü—Ä–æ–ø—É—Å–∫–∞–µ–º."
            )
            continue

        acc = evaluate_prompt(
            model,
            dataset_path,
            config["document_classes"],
            subsets,
            sample_size,
            candidate_prompt,
        )
        print(f"  ‚ûú Accuracy —Å –Ω–æ–≤—ã–º –ø—Ä–æ–º–ø—Ç–æ–º: {acc:.4f}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ—Ä—Å–∏—é –ø—Ä–æ–º–ø—Ç–∞
        out_path = PROMPTS_DIR / f"improved_prompt_attempt_{attempt}.txt"
        out_path.write_text(candidate_prompt, encoding="utf-8")
        print(f"  üìÑ –ü—Ä–æ–º–ø—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {out_path}")

        if acc > best_acc:
            print("  ‚úÖ –ù–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –ª—É—á—à–µ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ! –û–±–Ω–æ–≤–ª—è–µ–º –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç.")
            best_acc = acc
            best_prompt = candidate_prompt
        else:
            print("  üî∏ –ù–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –Ω–µ –ø—Ä–µ–≤–∑–æ—à—ë–ª –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç.")

    # --- –§–∏–Ω–∞–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ ---
    if best_acc > baseline_acc:
        print(
            f"\nüéâ –ù–∞–π–¥–µ–Ω —É–ª—É—á—à–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç! Accuracy: {best_acc:.4f} (–±—ã–ª–æ {baseline_acc:.4f})"
        )
        # –ü–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª
        prompt_path.write_text(best_prompt, encoding="utf-8")
        print(f"–ò—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª –ø—Ä–æ–º–ø—Ç–∞ –æ–±–Ω–æ–≤–ª—ë–Ω: {prompt_path}")
    else:
        print("\nüòê –ù–µ —É–¥–∞–ª–æ—Å—å —É–ª—É—á—à–∏—Ç—å –ø—Ä–æ–º–ø—Ç. –û—Å—Ç–∞—ë–º—Å—è –Ω–∞ –∏—Å—Ö–æ–¥–Ω–æ–π –≤–µ—Ä—Å–∏–∏.")


if __name__ == "__main__":
    main() 