# Описание модели для Benchmark

 семейства VLLM-моделей `Qwen2.5-VL`.

Материалы о семействе VLLM-моделей:
* [ссылка на GitHub](https://github.com/QwenLM/Qwen2.5-VL) 
* [ссылка на блог](https://qwenlm.github.io/blog/qwen2.5-vl)

Я исследовал возможности небольших моделей, которые умещаются на 1 GPU и имеют лицензию Apache-2.0:
* Qwen2.5-VL-3B-Instruct ([ссылка на HuggingFace](https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct))
* Qwen2.5-VL-7B-Instruct ([ссылка на HuggingFace](https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct))

# Docker контейнер модели

Поддерживаются модели:

P.S. Укажите одно из следующих названий при инициализации класса Qwen2VLModel(model_name="Qwen2.5-VL-3B-Instruct")

Варианты:
* Qwen2.5-VL-3B-Instruct
* Qwen2.5-VL-7B-Instruct


## Build Docker image

Для сборки `Docker image` выполним команду:
```
docker build -t ghcr.io/vlmhyperbenchteam/qwen2.5-vl:ubuntu22.04-cu124-torch2.4.0_v0.1.0 -f docker/Dockerfile-cu124 .
```

## Run Docker Container

Для запуска `Docker Container` выполним команду:
```
docker run \
    --gpus all \
    -it \
    -v .:/workspace \
    ghcr.io/vlmhyperbenchteam/qwen2.5-vl:ubuntu22.04-cu124-torch2.4.0_v0.1.0 sh
```

Нам откроется терминал внутри `Docker Container`.

Для запуска предсказаний выполним в нем команду:
```
cd cd workspace
python run_vqa.py
```

# Ключевые особенности моделей Qwen2-VL

1. Открытая лицензия - Apache-2.0 (Qwen2-VL-2B, Qwen2.5-VL-7B)
2. SoTA в понимании изображений и видео ([ссылка](https://github.com/QwenLM/Qwen2-VL#image-benchmarks), [демо  возможностей ссылка](https://qwenlm.github.io/blog/qwen2-vl/#model-capabilities))
3. Старшая модель превосходит GPT4o, Claude 3.5 Sonnet по многим бенчмаркам([ссылка](https://qwenlm.github.io/blog/qwen2-vl/#performance)).

 2B и 7B модели имеют почти такой же уровень точности на документах. Отлично подходят на роль локальной GPT4o .
* Qwen2-VL-2B занимает всего 6 Гб GPU RAM
* Qwen2-VL-7B занимает всего 17 Гб GPU RAM

4. Понимает длинный контекст, например многостраничный документ или видео 20 минут длинной.
5. Понимает много языков(может как считывать с их картинок, так и общается на них) ([ссылка на бенчмарк](https://github.com/QwenLM/Qwen2-VL#multilingual-benchmarks), [ссылка на пример](https://qwenlm.github.io/blog/qwen2-vl/#model-capabilities)):

Основные:
* EN – English (английский)
* ZH – Chinese (китайский)

На очень хорошем уровне:
* RU – Russian (русский)
* AR – Arabic (арабский)
* DE – German (немецкий)
* FR – French (французский)
* IT – Italian (итальянский)
* JA – Japanese (японский)
* KO – Korean (корейский)
* TH – Thai (тайский)
* VI – Vietnamese (вьетнамский)

6. Multi image inference - отвечает на вопрос просматривая сразу несколько сканов страниц длинного документа.
7. Регулируемый вход размера картинки.
* Модель может работать с картинками от 256 до 50176 пикселов.
* По умолчанию принимает документ в исходном разрешении а не сжимает его как все модели.
* Благодаря этому видит мельчащие подробности в документе, которые не видят другие модели из за сжатия картинки на входе.
* Для стабилизации объемов потребляемой памяти API модели позволяет указать диапазон разрешений входных сканов документов до которого они будут сжиматься.

8. Есть квантованные версии моделей ([ссылка](https://github.com/QwenLM/Qwen2-VL#performance-of-quantized-models)).

Они работают еще быстрее и потребляю меньше памяти. По метрикам ответов на датасете для оценивания ответов на вопросы на документах `DocVQA` проседают не так сильно.

9. Довольно быстрые для LLM ([ссылка](https://github.com/QwenLM/Qwen2-VL#speed-benchmark))
10. Поддерживают `Flash attention 2` для доп. ускорения инференса.
11. Есть инструкции по fine tuning и последующей квантизации полученных моделей.
12. Batch inference - предусмотрен.
13. Интегрирована с `HaggingFace` и `vLLM`.

Кроме того:
1.  Понимает диаграммы, графики, интерфейсы (Кажется подойдет и для `NLP`-кейса)
2.  Понимает математику
3.  Умеет анализировать видео по кадрам длинной до 20 минут.

 Может обобщать видеоконтент, отвечать на связанные с ним вопросы и поддерживать непрерывный диалог в режиме реального времени, предлагая поддержку в режиме реального времени в чате. Эта функциональность позволяет ему выступать в роли персонального помощника, помогая пользователям, предоставляя информацию, полученную непосредственно из видеоконтента.

# Результаты теста модели Qwen2.5-VL-7B-Instruct:

Для получения результатов выполняем:
```
python run_predict.py
```

## Пример счета на оплату:

Приведен пример синтетического документа, форма счета-фактуры найдена в Интернет.
Заполнена на основе генератора случайных чисел и не является реальным счетом на оплату.

![schet_na_oplatu](example_docs/1.png)

### вопросы по данному документу и ответы модели на них

Question:
```
Опиши документ.
```
  
Answer: 
```
Это документ "Счет-фактура" (СЧ-ФАКТУРА) от 28 сентября 2010 года, выданная компанией "Татэнерго". Документ содержит информацию о продавце, грузоотправителе, грузополучателе и покупателе, а также детализированную информацию о товарах или услугах, оказанных или выполненных.

### Основные данные:
- **Продавец**: Татэнерго
- **Адрес продавца**: 189569, к. Красная Поляна, пер. Севастопольский, д. 2/4
- **ИНН/КПП продавца**: 247899609419/199345731
- **Грузоотправитель**: Татэнерго
- **Адрес грузоотправителя**: 189569, к. Красная Поляна, пер. Севастопольский, д. 2/4
- **Грузополучатель**: РАО «Шашков-Меркушев»
- **Адрес грузополучателя**: 165596, ст. Раменское, пр. Автомобилистов, д. 930 к. 3
- **ИИН/КПП грузополучателя**: 292675119114/189443405
- **Валюта**: Российский рубль

### Товары/услуги:
1. **Наименование товара**: Пастух отдел мрачно.
   - **Количество**: 1 шт.
   - **Цена за единицу**: 9955 рублей
   - **Сумма налога**: 1792 рубля
   - **Сумма товаров с налогом**: 11747 рублей

2. **Наименование товара**: Возможна теория порода.
   - **Количество**: 1 шт.
   - **Цена за единицу**: 6742 рубля
```

